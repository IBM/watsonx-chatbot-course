{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#build-an-ai-powered-chatbot-with-wastonx","title":"Build an AI-powered chatbot with wastonx","text":"<p>Welcome to our lab! In this lab, we'll be using watsonx to accomplish building an AI-powered chatbot in less than an hour!</p> <p>The goals of this workshop are:</p> <ul> <li>Learning the power that is watsonx.</li> <li>Learning about IBM Cloud.</li> <li>Understanding why AI is our future.</li> </ul>"},{"location":"#about-these-labs","title":"About these labs","text":"<p>The introductory page of the workshop is broken down into the following sections:</p> <ul> <li>Agenda</li> <li>Technology Used</li> <li>Credits</li> </ul>"},{"location":"#agenda","title":"Agenda","text":"Lab 0: Pre-work Pre-work for the project Lab 1: Basic watsonx assistant Learn the basics of using Watson Assistant Lab 2: Refining watsonx assistant Refining your Watson Assistant Lab 3: Deploying your watsonx assistant Deploying your Watson Assistant"},{"location":"#technology-used","title":"Technology Used","text":"<ul> <li>IBM Cloud</li> <li>watsonx Assistant</li> </ul>"},{"location":"#credits","title":"Credits","text":"<ul> <li>JJ Asghar</li> <li>James Walsh</li> <li>Blake McGregor</li> <li>Peter Keller</li> </ul>"},{"location":"lab-1/","title":"Getting started with watsonx Assistant part I: the build guide","text":"<p>Chatbots are a great way for you to naturally and efficiently help your customers get stuff done, but most chatbot building tools today are either overly simplistic and break whenever someone asks your bot something unexpected, or focused only on a developer as the bot builder, making it very hard for content-focused individuals to collaborate.</p> <p></p> <p>We think it\u2019s about time a bot-building tool let anyone build robust AI-powered bots: bots that can automatically handle the craziness of human conversation and scale across a company without breaking. That\u2019s why watsonx Assistant has a build experience tailored to the people who directly interact with customers daily.</p> <p></p> <p>You don\u2019t have to sacrifice on powerful chatbot features either. watsonx Assistant will automatically handle all sorts of things that could go wrong during a conversation, such as topic changes, vague requests, misunderstandings, and asking for a human agent. In this post, we\u2019ll show you how to create a fully-built action in your new assistant in 30 minutes or less. Here\u2019s what you\u2019ll do:</p> <ol> <li>Learn the basics (5 min)</li> <li>Create your first assistant (5 min)</li> <li>Create your first conversation (15 min)</li> <li>Preview your assistant (5 min)</li> </ol>"},{"location":"lab-1/#1-learn-the-basics-5-min","title":"1. Learn the basics (5 min)","text":"<p>Actions and steps are the only two things you need to know to build an AI-powered virtual agent.</p> <p></p>"},{"location":"lab-1/#what-is-an-action","title":"What is an action?","text":"<p>An action is a problem or a task that your customer wants to resolve. Anything from paying a bill to getting an invoice to saying hello to asking about the weather could be an action in your assistant.</p> <p></p>"},{"location":"lab-1/#what-is-a-step","title":"What is a step?","text":"<p>A step is just a back-and-forth interaction between your assistant and your customer. Simply put, steps represent the clarification questions, final answers, or human agent handoff points in the action. Everything else that the step needs to function like the flow logic, response options, or storage of the user\u2019s response is contained within the structure of the action itself. You no longer need to create separate entities and intents as part of a dialog skill! In the example above, the assistant asks clarification questions before handing the conversation over to an agent (with the account number as context) to pay a cable bill, or guides the user to the online billing portal for internet or phone bills.</p> <p>Tip</p> <p>If you\u2019re an existing watsonx Assistant customer, we have a convenient way for you to use dialog and actions together in the new product experience by downloading and migrating your dialog skills! You can do this gradually over time to gain the advantages of important new features in actions while maintaining the work you\u2019ve built into your classic assistant.</p>"},{"location":"lab-1/#2-create-your-first-assistant-5-min","title":"2. Create your first assistant (5 min)","text":"<p>When you first launch the watsonx Assistant experience, you\u2019ll be prompted to create your first assistant:</p> <p></p> <p>Give it a name that represents the domain of topics you want it to handle. For example, if you are building an assistant to handle support questions in your billing department, you might start by calling it the \u201cBilling Assistant.\u201d Choose what language you want it to speak before continuing. Watson Assistant can handle virtually any global language.</p> <p>Tip</p> <p>If you haven\u2019t already thought about what you want your assistant to handle or where it will talk to your customers, check out our post on planning your assistant. You can also take advantage of one of the templates in our catalog for your first assistant. This will dramatically reduce your timeline, as well as teach you the ropes.</p> <p>From here, you\u2019ll start on the home page of your brand-new assistant:</p> <p></p> <p>You\u2019ve already done the first two steps, so take a moment to check out what\u2019s on your screen. Each section is organized with progress bars so you can see what you\u2019ve done and how far you have to go.</p> <p>In the top right of your screen you\u2019ll also find the Learning center. Click to expand and open the menu items to find tours, shortcuts to useful content, and more. All of this is aimed at getting you up and running as quickly as possible, so be sure to explore.</p> <p>Now it\u2019s time to build your first conversation. Follow along with our example or create your own!</p>"},{"location":"lab-1/#3-create-your-first-conversation-15-min","title":"3. Create your first conversation (15 min)","text":"<p>Let\u2019s build out a conversation flow using our billing example from before:</p> <p></p> <p>For an internet or phone bill, the customer will be sent to the online billing portal.</p> <p>For cable bills, our fictional company\u2019s policy dictates that a human agent has to take payment. In this case, the assistant needs to get the customer\u2019s account number first to speed things up with the human agent.</p> <p>Let\u2019s build it!</p>"},{"location":"lab-1/#create-your-first-action","title":"Create your first action","text":"<p>Start by creating your first action. Remember that actions represent the topics your assistant can handle, such as \u201cpay bill.\u201d</p> <p>Tip</p> <p>You will be prompted to create your first action from scratch or from a template. To follow along with our example you\u2019ll want to choose the first option, but we definitely recommend exploring the templates at your disposal as you build out your proof of concept. You\u2019ll find a number of options that are customer-ready, or that can expand on your first assistant\u2019s abilities.</p> <p></p>"},{"location":"lab-1/#create-your-first-example","title":"Create your first example","text":"<p>You need to \u201ctrain\u201d your assistant\u2019s topic-recognition AI by giving it some example sentences. Start with the first one here, something like: I want to pay my cable bill please.</p> <p></p>"},{"location":"lab-1/#create-your-first-step","title":"Create your first step","text":"<p>Now it\u2019s time to create the first step in the bill pay interaction. We\u2019ll start with the clarification question around the customer\u2019s account type:</p> <p></p> <p>Step 1 was already created for you, so move to it and add the clarification question in the Assistant says text box. Something along the lines of: What type of account are we talking here?</p> <p></p> <p>Then, select the type of customer response the assistant should wait for. In this case, options are the best choice. Add the three options for Cable, Internet, and Phone, and apply your changes.</p> <p></p> <p>Your first step should ultimately look something like this:</p> <p></p>"},{"location":"lab-1/#preview-your-action","title":"Preview your action","text":"<p>Now preview your action to make sure it works. To do this, hit the preview button in the bottom right corner of your screen. Try out a few interactions and see that it properly recognizes what you ask it. Try typing something other than your earlier training sentence.</p> <p></p>"},{"location":"lab-1/#create-another-clarification-step","title":"Create another clarification step","text":"<p>With your first step created and tested, let\u2019s finish this action by creating another step. As a reminder, we still need to build steps 2, 3, and 4:</p> <p></p> <p>Let\u2019s add step 2 next. Add a new step below step 1:</p> <p></p> <p>Next, add the clarification question asking for the account number. Something like: What\u2019s your account number?</p> <p>After you\u2019ve done that, you need to tell the assistant to look for a number in response to the question. From the response dropdown list, choose number:</p> <p></p> <p>Next, you need to add some flow logic. Remember, given the way this flow works, an account number should only be gathered in the case of a cable bill. To handle this scenario, you need to add a condition to your step. To do that, change the step to be taken with conditions instead of without:</p> <p></p> <p>Conditions are requirements which must be met for the step to be triggered. In this case, we want to condition on the answer to step 1 being Cable but not Internet or Phone. Setting this up is easy. Just make sure you have the condition set to step 1 is Cable:</p> <p></p> <p>Once you\u2019re finished setting the condition, your action should look something like this:</p> <p></p>"},{"location":"lab-1/#create-an-agent-handoff-step","title":"Create an agent handoff step","text":"<p>You\u2019re almost finished building this action! We just need to add steps 3 and 4, each of which provide the final outcome for the user:</p> <p></p> <p>Let\u2019s start with step 3. Add it below step 2 and add some text related to getting the user to an agent to pay their bill. Something like: Let me get you to an agent who can help you pay your cable bill!</p> <p></p> <p>Next, condition this step on step 1 is Cable just like you did in step 2:</p> <p></p> <p>Finally, for this step, we don\u2019t need to gather any information from the user, so you can leave the define customer response section empty.</p> <p>We should, however, set up the assistant to route this conversation to a human agent. To add that, change the and then setting to connect to a human agent (which will also end the action when it hands off):</p> <p></p> <p>In the prompt that comes up, you should insert the context that you gathered for the human agent to review. Namely, the fact that the customer wants to pay their cable bill as well as the account number.</p> <p>Tip</p> <p>To insert the information To insert information you\u2019ve collected into text, start with the $ sign, and a quick select box should appear like this:</p> <p></p> <p>Select step 2 (the account number) as the field you want to insert and apply your changes.</p> <p>Step 3 should be complete and look like this:</p> <p></p>"},{"location":"lab-1/#create-a-final-response-step","title":"Create a final response step","text":"<p>Lastly, add step 4. It should say something like: To pay your \\&lt;type of bill&gt; bill, you can head to our online portal \\&lt;link to portal&gt;</p> <p>To insert a variable like the type of bill being paid, click the variable insert button at the top of the text box:</p> <p></p> <p>And to add a link to the text, highlight the text you want to use and then click the link button:</p> <p></p> <p>The settings for the link should look something like this:</p> <p></p> <p>Next, make sure this step only fires for an internet or phone bill. To do that, create a condition for step 1 is Internet. Then add another condition for step 1 is Phone. When you do this, be sure that the step looks for any of these conditions to be met and not all of them:</p> <p></p> <p>Finally, make sure the action ends after this step is reached. To do that, change the And then setting to End the action.</p> <p></p> <p>Test the whole action Boom! Your steps should now be complete and look like this.</p> <p></p> <p>Now for the fun part, let\u2019s try it out!</p> <p></p> <p>Try a few scenarios where you state the type of bill up front. Notice how the assistant skips that question and moves immediately to the next step.</p> <p></p> <p>Add some more examples You may notice when testing that the assistant doesn\u2019t correctly recognize everything you ask it. To address this, you need to train the AI with more than just one example sentence. Simply move to the top of the action in the customer starts with section and add four more varied sentences:</p> <p></p> <p>Tip</p> <p>While you\u2019re at it, we recommend naming your action (top left of the image above) with something simple that your customers would recognize. In this case, maybe something like \u201cPay a bill.\u201d</p>"},{"location":"lab-1/#4-preview-your-assistant-5-min","title":"4. Preview your assistant (5 min)","text":"<p>To see how your assistant would work on one of your channels, head to the preview page:</p> <p></p> <p>This page is a representation of your \u201cdraft\u201d work in progress. It has an inline preview for you to test. You can also share your work with others on your team quickly with a shareable URL:</p> <p></p> <p>Simply click that button to copy the URL to your clipboard, then paste it into any messaging service to share your draft with members of your team. The embeddable web chat integration is included for you by default, and you can go to the integration catalog to add any other channels to your assistant, such as phone integration:</p> <p></p> <p>Congrats! You\u2019ve successfully learned all you need to know to get started with watsonx Assistant. From here, start building out the topics you really care about automating with your customers.</p> <p></p>"},{"location":"lab-2/","title":"Refining your watsonx assistant","text":"<p>Before we go into all the ways to refine your first assistant, take a moment to congratulate yourself! You did it, and you finished in record time. Who would have thought that a virtual assistant capable of helping customers pay their bills or reach a live agent could be launched in under 30 minutes?</p> <p>In Part 01, we created the action \u201cI want to pay my cable bill,\u201d plus you learned how to preview and share your first assistant so that you can immediately get your team experimenting with it AND contributing to its success.</p> <p>So, now that your rocket is off and the smoke has cleared the launch site, let\u2019s take a closer look at the payload your assistant is carrying right from the start.</p> <p>On your new assistant\u2019s homepage, we take you directly from the launch pad to mission control. Your introductory journey was aimed at learning the basics. This homepage contains all the features you\u2019ll need to grow and strengthen your assistant over its lifecycle.</p>"},{"location":"lab-2/#step-1-enhancing-your-assistant","title":"Step 1: Enhancing your assistant","text":""},{"location":"lab-2/#customize-your-assistants-greeting","title":"Customize your assistant\u2019s greeting","text":"<p>The first step in refining your assistant is personalizing how it greets customers. Go to your Actions menu and click Set by assistant (under all items), then on Greet customer, then on the first Conversation steps box where you can edit the greeting to make it your own.</p> <p>Some things to consider:</p> <ul> <li>Give your assistant a name that reflects your business</li> <li>Choose a greeting that describes your assistant\u2019s purpose</li> <li>Settle on a greeting that satisfies any number of customer scenarios. For our purposes:</li> </ul> <p>\"Hi, I\u2019m Telly \u2014 Need help with your service today?\u201d</p> <p></p> <p>Note: Don't forget there's a \"save\" icon located in the upper right hand side. After changing the greeting now's a good time to use it.</p>"},{"location":"lab-2/#lights-camera-more-actions","title":"Lights, camera, more actions!","text":"<p>Now that your assistant has a name and a purpose, it\u2019s time to expand the range of requests it can resolve.</p> <p>In our use case, data shows that your customers want information on bundling two or more services together. That request will be your focus as you build your second action.</p> <p>Go to your Actions menu again, but this time stay on the Created by you tab. Click New action in the top right corner, then type an example user request.</p> <p></p> <p>I want to add a service to my plan.</p> <p>As you\u2019ll recall from building your first action, you need to train your assistant with multiple example phrases. Click the arrow in the corner of the Customer starts with box, then add five alternate phrases.</p> <p>How can I add a service to my plan?</p> <p>Can I bundle multiple services?</p> <p>I want to bundle more than one service.</p> <p>Bundle internet and phone</p> <p></p> <p>Let\u2019s define a couple of responses, since we know customers will fall into one of two categories. Go into Edit response and type in two options: \u2018Compare pricing\u2019 and \u2018Bundle now\u2019.</p> <p>I can help you with that! Do you want to?</p> <p></p> <p>In the second and third steps, you\u2019ll define conditions and assistant responses for both above options.</p> <p></p> <p>You can see a list of prices and services at our pricing portal.</p> <p>Glad you've done your research! Let me connect you to an agent who can bundle your services!</p> <p>Your assistant is now able to resolve two separate customer needs, clearly demonstrating its business value!</p>"},{"location":"lab-2/#validate-your-steps","title":"Validate your steps","text":"<p>Human conversation isn\u2019t perfectly predictable. There will inevitably be times when users enter responses that don\u2019t provide the information your assistant needs. That\u2019s why we include Establish step validation in the Task Tracker.</p> <p>To ensure your assistant has what it needs to guide the user through an action with confidence, it will prompt the user to re-enter their response when it can\u2019t recognize the appropriate value.</p> <p>In our previous step, you defined responses for the user. If the user doesn\u2019t select either \u2018Bundle services\u2019 or \u2018Compare prices\u2019 and instead enters irrelevant values, your assistant will prompt the user to enter a valid option. If the user continues to enter invalid options, your assistant will route the action to a fallback option (more on that later!).</p> <p>Click Edit validation to personalize your assistant\u2019s response and adjust the number of attempts the user gets before going to the fallback action (the number of attempts is preset to three).</p> <p></p> <p>Your assistant will now ask for validation from this particular step by rephrasing the options, and it will only give your users two attempts before going to the fallback option.</p> <p></p>"},{"location":"lab-2/#ask-clarifying-questions","title":"Ask clarifying questions","text":"<p>Step validation is just one of the ways your assistant can keep the conversation going. If the customer\u2019s request doesn\u2019t match an action, and you haven\u2019t singled one out for fallback, the assistant will offer default choices from among its actions.</p> <p></p> <p>Turn this option on by clicking Set up your assistant to ask clarifying questions on the Task Tracker, and switching the toggle to \u2018on\u2019. You can also customize the phrasing in the Assistant says and Label for a fallback choice fields.</p> <p>Note: These are \"global\" so you'll need to \"x\" out of the specific action you're looking at.</p> <p></p>"},{"location":"lab-2/#what-to-do-when-no-action-matches","title":"What to do when no action matches","text":"<p>Your assistant is ready to support your customers with multiple tasks, but what happens when customers enter a request your assistant isn\u2019t trained to handle yet? This is where Retry comes in.</p> <p>Head back to the Actions menu, click Set by assistant to reveal actions preloaded into your assistant, then click No action matches.</p> <p></p> <p>Once inside, you can customize your assistant\u2019s responses. A good strategy is to state clearly what your assistant can and can\u2019t do. Trust us, your customers will thank you for saving them the headache.</p> <p>By planning for requests your assistant can\u2019t resolve, you can get your customers back on track to what the assistant can do.</p> <p>Type example requests into the Additional training examples field. In this case, let\u2019s write</p> <p>I want to go paperless</p> <p></p> <p>Then head over to Conversation steps and click the first box to edit the preloaded response as follows:</p> <p>I'm sorry, but I'm not trained to assist customers with that yet. I can help you pay your bill, add a service to your plan. Do you need help with either of these today?</p> <p></p> <p>Finally, here\u2019s what this example conversation would look like.</p> <p></p>"},{"location":"lab-2/#designating-a-fallback-action","title":"Designating a fallback action","text":"<p>If the assistant can\u2019t offer the customer their desired solution, the customer may rely on your assistant\u2019s built-in fallback action. Watson Assistant\u2019s fallback action is preset to escalate to a live agent.</p> <p>Your assistant will use the fallback action in three situations:</p> <ul> <li>Agent requested \u2013 triggered when the customer asks outright to speak to a live agent</li> <li>Step validation failed \u2013 triggered when the user can\u2019t understand the customer\u2019s request (covered above)</li> <li>No action matches \u2013 if you decide to forgo retry and skip directly to live agent support in your flow</li> </ul> <p></p> <p>You can customize these responses using conditions like any other action, or you can provide different responses based on agent availability. There is even a field to provide case background to a human agent!</p> <p></p> <p>Here\u2019s how a simple fallback looks in the assistant preview.</p> <p></p>"},{"location":"lab-2/#step-2-testing-and-refining-your-assistant","title":"Step 2: Testing and refining your assistant","text":""},{"location":"lab-2/#troubleshooting-and-debugging","title":"Troubleshooting and debugging","text":"<p>Very little can go wrong if you follow the above steps. But, you still want to double check that your assistant is firing correctly and functioning as it should.</p> <p>Click Access the preview panel and test using debug mode. Think of this as the first in a series of short audits you\u2019ll perform as you get closer to sharing the first version of your assistant. Click the ladybug icon at the top left of the Preview panel to activate debug mode.</p> <p></p> <p>This will provide a confidence score for each of the assistant\u2019s possible responses. You can navigate directly to the step inside each action that is triggering it to make adjustments on the fly.</p> <p></p>"},{"location":"lab-2/#optional-steps-add-depth-to-what-your-assistant-can-do","title":"Optional steps: add depth to what your assistant can do","text":"<p>Two items on the task list are labelled optional. Feel free to experiment with Create additional actions to flesh out your assistant. We certainly did! Some examples for Telly include \u201cI want to add a landline\u201d and \u201cIs my promo code valid?\u201d.</p> <p></p> <p></p> <p>The other optional task in the Task Tracker is to Refine the assistant based on team feedback.</p>"},{"location":"lab-2/#conclusion","title":"Conclusion","text":"<p>You\u2019ve worked through two important steps toward getting your first assistant live. You spent under 30 minutes setting up your basic assistant, and another 30 minutes expanding on it. You now have a trusted ally that can handle multiple customer requests, and you\u2019ve streamlined important aspects of your customer service flow. The only limit now is the sky.</p> <p></p>"},{"location":"lab-3/","title":"Deploying watsonx assistant","text":"<p>You built your first action with watsonx Assistant in Lab 1, then refined your content in Lab 2. Now let\u2019s learn how to test your assistant and deploy it on your website!</p>"},{"location":"lab-3/#publish-and-preview-your-assistants-content","title":"Publish and preview your assistant\u2019s content","text":"<p>Click the blue Publish button at the top of the table, and voila: you\u2019ve published your first version of your assistant\u2019s content! Your assistant is not visible to customers yet (we\u2019ll cover that process soon), but this version is preserved, and any subsequent edits you make will be saved in the draft environment.</p> <p></p> <p>Now it\u2019s time to share this first version of your content with your colleagues! Click the Preview icon (the play icon) to open up the Preview page.</p> <p></p> <p>The left-right navigation has three key links:</p> <ul> <li>Change background website: click this button and type/paste your organization\u2019s URL to make your homepage the background behind the chat panel</li> <li>Copy link to share: click this button to copy the Preview URL to your clipboard, then forward it to your team</li> <li>Customize web chat: this button takes you to the web chat editor where you can personalize your chat panel\u2019s elements</li> </ul> <p>Your colleagues are your best resource for refining your assistant\u2019s content: they know the business, your customers\u2019 pain points, and what questions most frequently need answering.</p>"},{"location":"lab-3/#best-practices-weve-identified-for-testing-your-assistant","title":"Best practices we\u2019ve identified for testing your assistant","text":"<ul> <li>Send the preview link to 10-15 colleagues</li> <li>Don\u2019t invite anybody who was part of the building process</li> <li>Ask your colleagues to spend 10 minutes interacting with the assistant</li> <li>Ask them to log and categorize any issues they had</li> <li>Instruct your testers to ask for a human agent if they get frustrated</li> <li>Make sure you collect at least 20-30 conversations</li> </ul> <p>When reviewing conversation logs and your colleagues\u2019 notes, the two main areas to focus on are:</p> <ul> <li>Understanding: Is your assistant properly understanding user requests? Are there frequent topics that you haven\u2019t trained your assistant to handle yet?</li> <li>Resolution: Are users successfully completing actions? Is the assistant escalating actions to human agents more frequently for certain actions?</li> </ul> <p>You can review the details of each conversation in the Conversations tab of your assistant\u2019s Analyze page (we\u2019ll give you a tour of that page later). Reviewing conversations is an ideal way to improve your assistant\u2019s actions. Once you deploy your assistant to your customers reviewing every conversation will be unrealistic, so take advantage of this early testing phase to rigorously refine your assistant\u2019s actions.</p>"},{"location":"lab-3/#customize-the-web-chat","title":"Customize the web chat","text":"<p>The web chat channel integration is automatically included with every instance of watsonx Assistant. Click Customize web chat on the Preview page or select Web chat on the home page to open the web chat editor.</p> <p></p> <p>Style, the first tab on the page, lets you name your assistant, adjust the text bubble and header colors, and add your company\u2019s avatar (you\u2019ll need to upload your avatar image to a URL to do this).</p> <p></p> <p>Home Screen is where you can edit your assistant\u2019s initial Greeting to the user. As the page states, \u201cGood greetings are welcoming, actionable, and expressive of your assistant\u2019s personality.\u201d</p> <p>Once you\u2019ve got a greeting that you\u2019re happy with, add Conversation starters in the field below. These conversation starters should be simple phrases that match your assistant\u2019s actions. They appear in the chat panel above the user input field.</p> <p></p> <p>When the user selects an option from among the starters, your assistant automatically funnels the user into the appropriate action \u2014 no heavy lifting required!</p> <p>The web chat editor is also where you configure Suggestions. Suggestions are automatically configured on when you create your assistant. Suggestions appear in the chat panel when your assistant receives a request it doesn\u2019t recognize. They\u2019re designed to funnel the user into an action, just like the Conversation starters.</p> <p></p> <p>The option label is preloaded with Connect to an agent. This option appears when the user clicks on the ? icon in the corner, or after three failed attempts (refer to Lab 2 for more info on this feature).</p>"},{"location":"lab-3/#get-acquainted-with-your-assistants-analytics","title":"Get acquainted with your assistant\u2019s analytics","text":"<p>Your assistant collects data from conversations with users in both the draft and the live environments. Once customers start interacting with your assistant, the Analyze page starts capturing data. This data will guide you as you continuously refine your assistant based on its success in resolving users\u2019 requests.</p> <p>Select Get acquainted with your assistant\u2019s analytics in the Task Tracker or click the chart icon to go to Analyze.</p> <p></p> <p>You have the option to view analytics from a fixed date range (just open the dropdown menu and select a range) or to view a custom range based on specific dates.</p> <p>The centerpiece of the Analyze page is the Completion and Recognition tables. The data in these tables show you how often your assistant can successfully guide users through the end of an action, and how often it recognizes user requests. Beneath the tables, you\u2019ll see lists of most frequent actions, least frequent actions, and least completed actions.</p> <p>The Conversations section lets you view actual interactions between end users and the assistant. You won\u2019t need to guess what\u2019s working and what isn\u2019t, because you\u2019ll have data tracking built into your assistant\u2019s payload, plus real-world examples of interactions between your assistant and its users. Once you\u2019ve taken the tour of the analytics and you\u2019re ready to make use of it, take a moment to congratulate yourself: you\u2019ve reached \u201cthe end of the beginning\u201d and have an assistant that\u2019s ready to meet your customers!</p>"},{"location":"lab-3/#deploy-your-assistant","title":"Deploy your assistant","text":"<p>There are two short steps left before your customers can chat with your assistant on your website:</p>"},{"location":"lab-3/#1-publish-your-latest-content-and-assign-it-to-the-live-environment","title":"1. Publish your latest content and assign it to the live environment","text":"<p>Return to the Publish page by clicking the rocket icon on the side menu, or by clicking Publish your latest content to the live environment in the Task Tracker. You\u2019ll see a list of all the edits you\u2019ve made since publishing V1 in the table. Click the blue Publish button to publish V2 of your content.</p> <p>To assign V2 to the live environment, go to your Environments page, click Assign a version, then select V2 in the modal.</p> <p></p> <p>Again, every time you publish a version of your assistant, you create a snapshot of your current content. The version assigned to the live environment will be the one your customers interact with, and any new content you add to your assistant will be saved in the draft environment until you\u2019re ready to publish it as a version.</p>"},{"location":"lab-3/#2-deploy-your-assistant-on-a-live-channel-across-a-broader-set-of-customers","title":"2. Deploy your assistant on a live channel across a broader set of customers","text":"<p>When you\u2019re ready to launch your assistant on your website, it\u2019s literally as easy as copy and paste! Return to the web chat editor and click the Embed tab.</p> <p>You\u2019ll see the JavaScript code snippet you\u2019ll need to integrate your assistant into your website. Click the copy icon next to the script, open the HTML source for any page on your website, and paste the snippet in.</p> <p>Tip</p> <p>Paste the snippet as close to the closing \\&lt;/body&gt; tag as possible to ensure that your page renders as fast as possible. Refer to the documentation for the new Watson Assistant to get the deepest dive possible on deploying your assistant to your website.</p> <p></p> <p>Not only is your assistant now live and ready to start answering customers\u2019 questions, you also have the option of deploying your assistant on as many of your site\u2019s pages as you want. Just make sure you only add the code snippet once per page.</p>"},{"location":"lab-3/#success-now-the-fun-begins","title":"Success! Now the fun begins","text":"<p>You now have a virtual agent live on your website, built, tested, and deployed in less than an hour! As great as this first version of your assistant is, you\u2019ve only scratched the surface of what it can do.</p> <p></p>"},{"location":"pre-work/","title":"Pre-work","text":"<p>This section is broken up into the following steps:</p> <ol> <li>Sign up for IBM Cloud</li> <li>Download or clone the repo</li> </ol>"},{"location":"pre-work/#1-sign-up-for-ibm-cloud","title":"1. Sign up for IBM Cloud","text":"<p>Ensure you have an IBM Cloud account.</p> <p></p>"},{"location":"pre-work/#2-download-or-clone-the-repo","title":"2. Download or clone the repo","text":"<p>Download the repo so that you can have it for local reference. So let's get that done early on. You'll need <code>git</code> on your laptop to clone the repository directly, or access to GitHub.com to download the zip file.</p> <p>To clone the repo, run the following commands:</p> <pre><code>git clone https://github.com/IBM/watsonx-chatbot-lab\ncd watsonx-chatbot-lab\n</code></pre>"},{"location":"resources/ADMIN/","title":"Admin Guide","text":"<p>This section is comprised of the following steps:</p> <ol> <li>Instructor Step</li> </ol>"},{"location":"resources/ADMIN/#1-instructor-step","title":"1. Instructor Step","text":"<p>Things specific to instructors can go here.</p>"},{"location":"resources/CONTRIBUTORS/","title":"Contributors","text":""},{"location":"resources/CONTRIBUTORS/#remko-de-knikker","title":"Remko de Knikker","text":"<ul> <li>Github: remkohdev</li> <li>Twitter: @remkohdev</li> <li>LinkedIn: remkohdev</li> <li>Medium: @remkohdev</li> </ul>"},{"location":"resources/CONTRIBUTORS/#steve-martinelli","title":"Steve Martinelli","text":"<ul> <li>Github: stevemar</li> <li>Twitter: @stevebot</li> <li>LinkedIn: stevemar</li> </ul>"},{"location":"resources/MKDOCS/","title":"mkdocs examples","text":"<p>This page includes a few neat tricks that you can do with <code>mkdocs</code>. For a complete list of examples visit the mkdocs documentation.</p>"},{"location":"resources/MKDOCS/#code","title":"Code","text":"<pre><code>print(\"hello world!\")\n</code></pre>"},{"location":"resources/MKDOCS/#code-with-line-numbers","title":"Code with line numbers","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"resources/MKDOCS/#code-with-highlights","title":"Code with highlights","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"resources/MKDOCS/#code-with-tabs","title":"Code with tabs","text":"Tab Header <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> Another Tab Header <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre>"},{"location":"resources/MKDOCS/#more-tabs","title":"More tabs","text":"Windows <p>If on windows download the <code>Win32.zip</code> file and install it.</p> MacOS <p>Run <code>brew install foo</code>.</p> Linux <p>Run <code>apt-get install foo</code>.</p>"},{"location":"resources/MKDOCS/#checklists","title":"Checklists","text":"<ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt</li> <li> In hac habitasse platea dictumst</li> </ul>"},{"location":"resources/MKDOCS/#add-a-button","title":"Add a button","text":"<p>Launch the lab</p> <p>Visit IBM Developer</p> <p>Sign up! </p>"},{"location":"resources/MKDOCS/#call-outs","title":"Call outs","text":"<p>Tip</p> <p>You can use <code>note</code>, <code>abstract</code>, <code>info</code>, <code>tip</code>, <code>success</code>, <code>question</code> <code>warning</code>, <code>failure</code>, <code>danger</code>, <code>bug</code>, <code>quote</code> or <code>example</code>.</p> <p>Note</p> <p>A note.</p> <p>Abstract</p> <p>An abstract.</p> <p>Info</p> <p>Some info.</p> <p>Success</p> <p>A success.</p> <p>Question</p> <p>A question.</p> <p>Warning</p> <p>A warning.</p> <p>Danger</p> <p>A danger.</p> <p>Example</p> <p>A example.</p> <p>Bug</p> <p>A bug.</p>"},{"location":"resources/MKDOCS/#call-outs-with-code","title":"Call outs with code","text":"<p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> <p>Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.</p>"},{"location":"resources/MKDOCS/#formatting","title":"Formatting","text":"<p>In addition to the usual italics, and bold there is now support for:</p> <ul> <li>highlighted</li> <li>underlined</li> <li>strike-through</li> </ul>"},{"location":"resources/MKDOCS/#tables","title":"Tables","text":"OS or Application Username Password Windows VM <code>Administrator</code> <code>foo</code> Linux VM <code>root</code> <code>bar</code>"},{"location":"resources/MKDOCS/#emojis","title":"Emojis","text":"<p>Yes, these work.  </p>"},{"location":"resources/MKDOCS/#images","title":"Images","text":"<p>Nunc eu odio eleifend, blandit leo a, volutpat sapien</p>"},{"location":"resources/MKDOCS/#right-align-image","title":"right align image","text":"<p>Nunc eu odio eleifend, blandit leo a, volutpat sapien</p>"},{"location":"resources/RESOURCES/","title":"Additional resources","text":""},{"location":"resources/RESOURCES/#ibm-demos","title":"IBM Demos","text":"<ul> <li>Collection: InfoSphere Information Server</li> <li>Tutorial: Transforming your data with IBM DataStage</li> </ul>"},{"location":"resources/RESOURCES/#redbooks","title":"Redbooks","text":"<ul> <li>IBM InfoSphere DataStage Data Flow and Job Design</li> <li>InfoSphere DataStage Parallel Framework Standard Practices</li> </ul>"},{"location":"resources/RESOURCES/#videos","title":"Videos","text":"<ul> <li>Video: Postal codes and part numbers (DataStage)</li> <li>Video: Find relationships between sales, employees, and customers (Information Analyzer)</li> <li>Video: Clean and analyze data (Governance Catalog)</li> </ul>"}]}